{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fmpsdk as fmp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zm_if\\anaconda3\\envs\\bigdata1\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zm_if\\anaconda3\\envs\\bigdata1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zm_if\\anaconda3\\envs\\bigdata1\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"crypt_cot\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbench_url = \"jdbc:mysql://localhost:3306/finance_out?permitMysqlSchema\"\n",
    "driver = \"com.mysql.jdbc.Driver\"\n",
    "data_base_crypto = \"new_crypto_data\"\n",
    "data_base_cot = \"cot_report\"\n",
    "table = \"btc_data\"\n",
    "cot_btc_table = \"BT\"\n",
    "mssql_url = f\"jdbc:sqlserver://ZAHRA\\SQLEXPRESS:61254;database={data_base_crypto};trustServerCertificate=true;encrypt=true\"\n",
    "mssql_cot_url = f\"jdbc:sqlserver://ZAHRA\\SQLEXPRESS:61254;database={data_base_cot};trustServerCertificate=true;encrypt=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_data = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\",mssql_cot_url) \\\n",
    "    .option(\"user\",\"mehassan\") \\\n",
    "    .option(\"password\",'password') \\\n",
    "    .option(\"dbtable\",cot_btc_table) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------+---------------------------+-----------------------+------------------------+-----------+--------------+\n",
      "|               date|noncomm_positions_long_all|noncomm_positions_short_all|comm_positions_long_all|comm_positions_short_all|comm_spread|non_comm_spred|\n",
      "+-------------------+--------------------------+---------------------------+-----------------------+------------------------+-----------+--------------+\n",
      "|2021-04-06 00:00:00|                      5938|                       8230|                    504|                     204|        300|         -2292|\n",
      "|2019-05-07 00:00:00|                      2946|                       3985|                      0|                      46|        -46|         -1039|\n",
      "|2021-09-28 00:00:00|                      4539|                       5422|                    479|                     301|        178|          -883|\n",
      "+-------------------+--------------------------+---------------------------+-----------------------+------------------------+-----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cot_data.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_data_preprocessed = cot_data.select(\"date\",\"comm_spread\")\n",
    "cot_data_preprocessed = cot_data_preprocessed.withColumnRenamed(\"comm_spread\",\"btc_com_spread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- btc_com_spread: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cot_data_preprocessed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- BTC: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_data_refined.printSchema()\n",
    "crypto_data_refined = crypto_data_refined.withColumn(\"date\",col(\"date\").cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- BTC: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_data_refined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_data = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\",mssql_url) \\\n",
    "    .option(\"user\",\"mehassan\") \\\n",
    "    .option(\"password\",'password') \\\n",
    "    .option(\"dbtable\",table) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_data_refined = crypto_data.select(\"date\",\"close\")\n",
    "crypto_data_refined = crypto_data_refined.withColumnRenamed(\"close\",\"BTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|      date|      BTC|\n",
      "+----------+---------+\n",
      "|2021-08-02|  39152.3|\n",
      "|2014-09-24|433.15178|\n",
      "|2023-04-20| 28248.18|\n",
      "+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_data_refined.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_crypto_data = crypto_data_refined.join(cot_data_preprocessed,on =\"date\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_data_preprocessed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row((sum(btc_com_spread) IS NULL)=False)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_crypto_data.select(sum(\"btc_com_spread\").isNull()).collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3762"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_crypto_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\",workbench_url) \\\n",
    "    .option(\"user\",\"mysql_user\") \\\n",
    "    .option(\"password\",'mu!tFL^fh5kE#6z8\"4dyBs') \\\n",
    "    .option(\"dbtable\",\"historical_with_sentiment\") \\\n",
    "    .option(\"driver\",driver) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = news_data.select(\"symbol\").distinct().rdd.flatMap(lambda x : x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbols = [\n",
    "    'AAPL', 'MSFT', 'NVDA', 'META', 'AMZN', 'TSLA', 'GOOGL',\n",
    "    'DBD', 'DSGX', 'GTLB', 'LOGI', 'CRSR',\n",
    "    'LNG', 'SWN', 'APA', 'BTU', 'CL',\n",
    "    'BMY', 'THC', 'TNDM',\n",
    "    'MOS', 'AXTA', 'KOP',\n",
    "    'SBLK', 'EME', 'DNOW',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CVX', 'ON', 'XOM'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stocks) - set(stock_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_data = {}\n",
    "for i in stocks:\n",
    "    individual_data[i] = news_data.filter(news_data[\"symbol\"] == i)\n",
    "    individual_data[i] = individual_data[i].select(\"date\",\"Close\",\"sentiment\")\n",
    "    individual_data[i] = individual_data[i].withColumnRenamed(\"Close\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_url = \"jdbc:mysql://localhost:3306/big_data?permitMysqlSchema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.utils import AnalysisException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL',\n",
       " 'LOGI',\n",
       " 'XOM',\n",
       " 'BMY',\n",
       " 'META',\n",
       " 'LNG',\n",
       " 'TSLA',\n",
       " 'EME',\n",
       " 'SWN',\n",
       " 'AXTA',\n",
       " 'CL',\n",
       " 'SBLK',\n",
       " 'CVX',\n",
       " 'TNDM',\n",
       " 'GTLB',\n",
       " 'GOOGL',\n",
       " 'APA',\n",
       " 'ON',\n",
       " 'MOS',\n",
       " 'DBD',\n",
       " 'DSGX',\n",
       " 'KOP',\n",
       " 'BTU',\n",
       " 'THC',\n",
       " 'AMZN',\n",
       " 'MSFT',\n",
       " 'CRSR',\n",
       " 'DNOW',\n",
       " 'NVDA']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "MSFT\n",
      "NVDA\n",
      "META\n",
      "AMZN\n",
      "TSLA\n",
      "GOOGL\n",
      "DBD\n",
      "DSGX\n",
      "GTLB\n",
      "LOGI\n",
      "CRSR\n",
      "LNG\n",
      "SWN\n",
      "APA\n",
      "BTU\n",
      "CL\n",
      "BMY\n",
      "THC\n",
      "TNDM\n",
      "MOS\n",
      "AXTA\n",
      "KOP\n",
      "SBLK\n",
      "EME\n",
      "DNOW\n"
     ]
    }
   ],
   "source": [
    "individual_data = {}\n",
    "try :\n",
    "    for i in stock_symbols:\n",
    "        individual_data[i] = news_data.filter(news_data[\"symbol\"] == i)\n",
    "        individual_data[i] = individual_data[i].select(\"date\",\"Close\",\"sentiment\")\n",
    "        individual_data[i] = individual_data[i].withColumnRenamed(\"Close\",i)\n",
    "        if individual_data[i] != \"XOM\" or \"ON\" or \"CVX\":\n",
    "            individual_data[i].write.format(\"jdbc\") \\\n",
    "                .option(\"url\",output_url) \\\n",
    "                .option(\"driver\",driver) \\\n",
    "                .option(\"dbtable\",f\"{i}\") \\\n",
    "                .option(\"user\",\"root\") \\\n",
    "                .option(\"password\",\"password\") \\\n",
    "                .save()\n",
    "            print(i)\n",
    "except AnalysisException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date=datetime.date(2024, 2, 28), AAPL=181.4199981689453, sentiment='1'),\n",
       " Row(date=datetime.date(2024, 2, 29), AAPL=180.75, sentiment='1'),\n",
       " Row(date=datetime.date(2024, 3, 1), AAPL=179.66000366210938, sentiment='1')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_data[\"AAPL\"].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------+---------+---------+\n",
      "|symbol|      date|            Close|   Volume|sentiment|\n",
      "+------+----------+-----------------+---------+---------+\n",
      "|  AAPL|2024-02-27|182.6300048828125| 54318900|        1|\n",
      "|  AAPL|2024-02-28|181.4199981689453| 48953900|        1|\n",
      "|  AAPL|2024-02-29|           180.75|136682600|        1|\n",
      "+------+----------+-----------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "individual_data[\"AAPL\"].filter(individual_data[\"AAPL\"][\"sentiment\"] != np.nan).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(individual_data[\"AAPL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in individual_data.keys():\n",
    "    individual_data[i].select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = news_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(data):\n",
    "    data[\"Sentiment\"] = \"\"\n",
    "    sentiment = []\n",
    "    for i in data['text']:\n",
    "        tokenized_news = tokenizer(i,return_tensors=\"tf\")\n",
    "        logits = model.predict(tokenized_news).logits\n",
    "        probabilities = tf.nn.softmax(logits)\n",
    "        sentiment.append(probabilities)\n",
    "    data[\"Sentiment\"] = sentiment\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentiment = sentiment_analysis(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = data_sentiment[[\"symbol\",\"Sentiment\"]].sort_values(by=\"symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_symbol = news_df[\"symbol\"].unique()\n",
    "news_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_news = {}\n",
    "for i in news_symbol:\n",
    "    news = []\n",
    "    news_for_symbol = news_df[news_df[\"symbol\"] == i]\n",
    "    for sentiment in news_for_symbol[\"Sentiment\"]:\n",
    "        news.append(sentiment)\n",
    "    data_news[i] = news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sentiment = {}\n",
    "for symbol, tensors in data_news.items():\n",
    "    mean_tensor = tf.reduce_mean(tensors,axis=0)\n",
    "    average_sentiment[symbol] = np.argmax(tf.nn.softmax(mean_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])\n",
    "model.config.id2label[predicted_class_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
